{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "feeb3173-7904-5a47-b1bb-1581e12d7f78",
        "openai_ephemeral_user_id": "d7c77d78-fd66-51c2-b57f-f214a5bb657e",
        "openai_subdivision1_iso_code": "AU-ACT"
      }
    },
    "noteable": {
      "last_transaction_id": "61fb5174-25b8-4085-af3d-f35b8eba07f0"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "c6ae5c0b-52b3-442c-aa1c-685b11d93a95",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "!pip install PyGithub",
      "outputs": []
    },
    {
      "id": "7e29375e-1807-4eea-ac91-5c663c4d280d",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "!pip install PyGithub",
      "outputs": []
    },
    {
      "id": "11660146-1c42-4d7b-a996-532dba3154c2",
      "cell_type": "markdown",
      "source": "# Python Cloud-Based Software Research\n## Brainstorming\nPython is a versatile language that is used in many application domains. Here are some areas where Python is commonly used and could be of interest to other software developers:\n- **Web and Internet Development**: Python offers many choices for web development, including frameworks like Django and Pyramid, micro-frameworks like Flask and Bottle, and advanced content management systems like Plone and django CMS. Python's standard library supports many Internet protocols, and there are many third-party libraries available for tasks like HTTP requests, HTML parsing, and network programming.\n- **Scientific and Numeric Computing**: Python is widely used in scientific and numeric computing, with libraries like SciPy for mathematics, science, and engineering, Pandas for data analysis and modeling, and IPython for an interactive shell that supports visualizations and parallel computing.\n- **Education**: Python is a superb language for teaching programming, both at the introductory level and in more advanced courses.\n- **Desktop GUIs**: Python can be used to create desktop applications, with several GUI libraries and toolkits available.\n- **Software Development**: Python is often used as a support language for software developers, for build control and management, testing, and many other ways.\n- **Business Applications**: Python is used to build ERP and e-commerce systems, with software like Odoo and Tryton offering a range of business applications.\n\n## Evaluation\nEach of these areas has its own potential benefits and challenges. For example, web and internet development with Python can be a powerful way to create dynamic websites and web applications, but it also requires a good understanding of web protocols and standards. Scientific and numeric computing with Python can enable complex calculations and simulations, but it may require a strong background in the relevant scientific or mathematical fields.\n\n## Expansion\nDepending on the specific needs and interests of the software developers who will be browsing your GitHub repository, different Python applications may be more or less relevant. For example, if your audience is primarily data scientists, they may be most interested in Python libraries for data analysis and machine learning. If your audience is web developers, they may be more interested in Python frameworks for web development.\n\n## Decision-Making\nThe final decision on what Python cloud-based software to focus on will depend on a combination of factors, including your own expertise and interests, the needs and interests of your audience, and the current trends and opportunities in the field of Python development. It may be helpful to conduct further research, such as surveys or interviews with potential users, to better understand their needs and interests.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "526f1bf5-637e-4779-abbc-54fbeeedca4a",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "fa7d22fb-7c54-4ec0-8d26-7b0ef100f7e8"
        },
        "ExecuteTime": {
          "end_time": "2023-05-26T04:43:05.336615+00:00",
          "start_time": "2023-05-26T04:43:04.644577+00:00"
        }
      },
      "execution_count": null,
      "source": "import os\nfrom github import Github\n\n# First create a Github instance using an access token\ng = Github(os.getenv('GITHUB_TOKEN'))\n\n# Then get your specific repository\nrepo = g.get_repo('matthewhand/stripe-payment')\n\n# Content for the README.md file\ncontent = '''# Stripe Payment\nThis repository contains information and code examples for setting up a Stripe payment system.'''\n\n# Check if README.md already exists\ntry:\n    readme = repo.get_contents('README.md')\n    # If it exists, update it\n    repo.update_file(readme.path, 'Update README.md', content, readme.sha)\nexcept:\n    # If it doesn't exist, create it\n    repo.create_file('README.md', 'Create README.md', content)",
      "outputs": []
    },
    {
      "id": "4e0f76f5-4c56-49c6-97bf-154113247618",
      "cell_type": "markdown",
      "source": "# Priorities\n## 1. Noteable Backup with Macie\n### 2. The Sims 4 with ChatGPT\n#### 3. Discord LLMBot (ChatGPT and Llama)",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "bb57a408-3a00-46ab-8964-af216e02e06e",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "d8f388f3-e4f0-4132-afb3-337ee3973a1f"
        },
        "ExecuteTime": {
          "end_time": "2023-05-26T04:44:09.447497+00:00",
          "start_time": "2023-05-26T04:44:04.041757+00:00"
        }
      },
      "execution_count": null,
      "source": "!pip install PyGithub",
      "outputs": []
    },
    {
      "id": "68fe9707-a8e2-4797-bb14-e52ac4900244",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "e0adb792-9f45-4593-a7ef-99298bbfcfbc"
        },
        "ExecuteTime": {
          "end_time": "2023-05-26T04:44:34.506187+00:00",
          "start_time": "2023-05-26T04:44:33.826215+00:00"
        }
      },
      "execution_count": null,
      "source": "import os\nfrom github import Github\n\n# First create a Github instance using an access token\ng = Github(os.getenv('GITHUB_TOKEN'))\n\n# Then get your specific repository\nrepo = g.get_repo('matthewhand/stripe-payment')\n\n# Content for the README.md file\ncontent = '''# Stripe Payment\nThis repository contains information and code examples for setting up a Stripe payment system.'''\n\n# Check if README.md already exists\ntry:\n    readme = repo.get_contents('README.md')\n    # If it exists, update it\n    repo.update_file(readme.path, 'Update README.md', content, readme.sha)\nexcept:\n    # If it doesn't exist, create it\n    repo.create_file('README.md', 'Create README.md', content)",
      "outputs": []
    },
    {
      "id": "8c320bd0-df63-4d5f-aacc-4b4dcc654d7f",
      "cell_type": "markdown",
      "source": "# Priorities\n## 1. Noteable Backup with Macie\n### 2. The Sims 4 with ChatGPT\n#### 3. Discord LLMBot (ChatGPT and Llama)\n##### 4. Instructions on how to ChatGPT Blog like this",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "66922e45-cc4a-427e-a417-27bccf24b595",
      "cell_type": "markdown",
      "source": "# Interacting with ChatGPT Iteratively\n\nChatGPT is a powerful language model developed by OpenAI. It's designed to generate human-like text based on the input it's given. One of the unique features of ChatGPT is its ability to carry on a conversation, making it ideal for interactive applications. This essay will guide you through the process of interacting with ChatGPT iteratively, just like in a real conversation.\n\n## Understanding ChatGPT\n\nBefore we dive into the specifics of iterative interaction, it's important to understand what ChatGPT is and how it works. GPT stands for 'Generative Pretrained Transformer', which is a type of language model that uses machine learning to produce human-like text. 'ChatGPT' is a version of this model that's been fine-tuned for conversational purposes.\n\nWhen you interact with ChatGPT, you provide an input (often called a 'prompt'), and the model generates a response based on that input. The model doesn't know anything about the world or have any beliefs or desires - it simply predicts what text is likely to come next, based on the patterns it learned during training.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "ec58c003-d716-4b33-a4df-0c9fcc4be58c",
      "cell_type": "markdown",
      "source": "## Starting a Conversation\n\nInteracting with ChatGPT is like having a conversation. You start by providing an initial prompt, which can be a statement, a question, or anything else you want to talk about. For example, you might start with something like 'Tell me about the history of computer science.' ChatGPT will then generate a response that continues the conversation.\n\nIt's important to note that the quality of the output can be influenced by the quality of the input. Clear, specific prompts are more likely to result in clear, specific responses. If your prompt is vague or ambiguous, the model's response may also be vague or ambiguous.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "0be4d075-5ab0-4beb-94d1-4bb5570c39a6",
      "cell_type": "markdown",
      "source": "## Starting a Conversation\n\nInteracting with ChatGPT is like having a conversation. You start by providing an initial prompt, which can be a statement, a question, or anything else you want to talk about. For example, you might start with something like 'Tell me about the history of computer science.' ChatGPT will then generate a response that continues the conversation.\n\nIt's important to note that the quality of the output can be influenced by the quality of the input. Clear, specific prompts are more likely to result in clear, specific responses. If your prompt is vague or ambiguous, the model's response may also be vague or ambiguous.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "c384d472-aa01-4eb7-81c7-5144cebe3129",
      "cell_type": "markdown",
      "source": "## Continuing the Conversation\n\nOnce you've started a conversation, you can continue it by providing more prompts. Each new prompt should take into account the model's previous responses, just like in a real conversation. This is what we mean by 'iterative' interaction - the conversation evolves over time, with each new prompt building on what's come before.\n\nFor example, if ChatGPT's response to your initial prompt was a brief overview of the history of computer science, you might follow up with a more specific question, like 'Who were some of the key figures in the early days of computer science?' The model would then generate a new response based on this prompt, continuing the conversation.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "e5e2851c-1f8a-4b73-9fd6-e46bb307dae0",
      "cell_type": "markdown",
      "source": "## Managing the Conversation\n\nAs you interact with ChatGPT, you'll likely find that the conversation sometimes veers off in unexpected directions. This is a natural result of the model's generative nature - it's predicting what comes next based on patterns in the data it was trained on, not following a pre-defined script. If the conversation strays too far from the topic you're interested in, you can steer it back on course by providing a new prompt that refocuses the discussion.\n\nYou also have control over the length and complexity of the model's responses. By adjusting the 'max tokens' parameter, you can limit how long the model's responses are. If you want shorter, more concise responses, you can set 'max tokens' to a lower value. If you want longer, more detailed responses, you can set 'max tokens' to a higher value.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "8621c4e2-eb1c-48a2-a6e6-b9edfd7ae1c0",
      "cell_type": "markdown",
      "source": "## Managing the Conversation\n\nAs you interact with ChatGPT, you'll likely find that the conversation sometimes veers off in unexpected directions. This is a natural result of the model's generative nature - it's predicting what comes next based on patterns in the data it was trained on, not following a pre-defined script. If the conversation strays too far from the topic you're interested in, you can steer it back on course by providing a new prompt that refocuses the discussion.\n\nYou also have control over the length and complexity of the model's responses. By adjusting the 'max tokens' parameter, you can limit how long the model's responses are. If you want shorter, more concise responses, you can set 'max tokens' to a lower value. If you want longer, more detailed responses, you can set 'max tokens' to a higher value.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "d295dffc-c551-4adb-bd5c-77ac06194719",
      "cell_type": "markdown",
      "source": "## Advanced Techniques\n\nWhile the basic process of interacting with ChatGPT is straightforward, there are also more advanced techniques you can use to fine-tune the model's behavior. For example, you can use the 'temperature' parameter to control the randomness of the model's responses. A higher temperature will make the model's responses more random, while a lower temperature will make them more deterministic.\n\nYou can also use 'system' level instructions to guide the model's behavior. For example, you might start a conversation with a system instruction like 'You are an assistant that speaks like Shakespeare.' The model will then generate responses in a Shakespearean style.\n\nFinally, remember that while ChatGPT is a powerful tool, it's not perfect. It can sometimes produce incorrect or nonsensical responses, and it should be used with care and supervision. Always review the model's outputs before using them in a public or sensitive context.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "b3ca7056-3db3-4b25-9412-884a0f8e3ff7",
      "cell_type": "markdown",
      "source": "# Organizing Multiple Essays\n\nWhen it comes to organizing multiple essays, especially in a technical context like a GitHub repository, there are several strategies you can consider. The best approach depends on various factors, including the number of essays, their length, the topics they cover, and the intended audience. Here, we'll discuss two main strategies: storing all essays in a single file (like README.md) and storing each essay in a separate file. We'll compare these strategies in terms of accessibility, readability, maintainability, and navigability.\n\n| Strategy | Accessibility | Readability | Maintainability | Navigability |\n| --- | --- | --- | --- | --- |\n| Single File | High: Users only need to access one file. | Can be low if the file becomes too long. | Can be difficult if many updates are needed. | Can be difficult if the file becomes too long. |\n| Multiple Files | Can be high, but users need to know where each file is. | High: Each file can be focused on a single topic. | High: Each file can be updated independently. | High: Users can navigate directly to the file they're interested in. |\n\n## Single File Strategy\n\nStoring all essays in a single file, like README.md, has the advantage of simplicity. Users only need to access one file to read all the essays. This can be especially convenient if the essays are closely related and readers are likely to want to read all of them. However, this strategy can become problematic if the file becomes too long. It can be difficult to navigate, and readers may find it overwhelming. It can also be difficult to maintain if many updates are needed.\n\n## Multiple Files Strategy\n\nStoring each essay in a separate file can make the repository more organized and easier to navigate. Each file can be focused on a single topic, making it easier for readers to find the information they're interested in. This strategy also makes it easier to maintain the repository, as each file can be updated independently. However, this strategy requires users to know where each file is, which can be a barrier to accessibility.\n\nIn conclusion, the best strategy depends on the specific circumstances. If the essays are closely related and the total length is not too long, the single file strategy might be the best choice. If the essays cover different topics or are quite long, the multiple files strategy might be better.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "909cd1c0-dca4-43de-bf0f-30ea63f9b9a6",
      "cell_type": "markdown",
      "source": "breeds of dogs, their characteristics, and their origins?' The more specific prompt helps guide the model to provide a more detailed and focused response.\n\nPrompt engineering can be particularly useful when you're using the model for a specific task, like writing an essay or generating code. By carefully crafting your prompts, you can guide the model to produce the kind of output you need.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "10899121-4c23-451f-aeb7-dc3a63b026f3",
      "cell_type": "markdown",
      "source": "## Priorities\n\nHere are the updated priorities, with the new top priority 'StripePayment' added:\n\n1. **StripePayment**\n2. Noteable Backup with Macie\n3. The Sims 4 with ChatGPT\n4. Discord LLMBot (ChatGPT and Llama)\n5. Instructions on how to ChatGPT Blog like this\n\nEach of these priorities represents a different project or task. The order of the priorities indicates their relative importance, with higher priorities listed first.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "1b83ec2b-7bd8-4f36-855d-54d9bde11392",
      "cell_type": "markdown",
      "source": "## Using the 'Continue' Prompt\n\nIn some cases, you might find that a response from ChatGPT is cut off or unfinished. This can happen if the response is too long, or if there was an error during the generation process. When this happens, you can use the 'continue' prompt to ask ChatGPT to continue where it left off.\n\nFor example, if ChatGPT was in the middle of explaining a concept and the response was cut off, you could simply respond with 'continue.' ChatGPT would then generate more text to continue the explanation.\n\nIt's important to note that this doesn't always work perfectly. Because ChatGPT doesn't have a memory of past requests or responses, it doesn't always know exactly where to pick up. However, it will do its best to generate a continuation that makes sense based on the context it has.\n\nThis can also be useful if a plugin fails during a generation. Depending on how the plugin failed, it may still be possible to retry the generation by responding with 'continue.'",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "68b81774-31b0-4305-be26-26dc7b762ceb",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "7a037fbc-0e8c-4aa2-b366-a91bc95d7ef4"
        },
        "ExecuteTime": {
          "end_time": "2023-05-26T05:02:55.647277+00:00",
          "start_time": "2023-05-26T05:02:55.487131+00:00"
        }
      },
      "execution_count": null,
      "source": "import os\n\nGITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\nNETFLIFY_API_KEY = os.getenv('NETFLIFY_API_KEY')\n\nGITHUB_TOKEN, NETFLIFY_API_KEY",
      "outputs": []
    },
    {
      "id": "54586191-a348-49d2-afe6-4a7276a05957",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "64342f13-3858-4a3e-b74c-3467805d2ce4"
        },
        "ExecuteTime": {
          "end_time": "2023-05-26T05:03:43.701720+00:00",
          "start_time": "2023-05-26T05:03:43.540921+00:00"
        }
      },
      "execution_count": null,
      "source": "NETLIFY_API_KEY = os.getenv('NETLIFY_API_KEY')\nNETLIFY_API_KEY",
      "outputs": []
    }
  ]
}